{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56cd9e2-8a4a-49a7-abff-13b44ee50c4a",
   "metadata": {},
   "source": [
    "# Scraping Data Science Job\n",
    "\n",
    "Untuk melakukan *web scraping*, kita gunakan library `Scrapy`. **Scrapy** adalah sebuah framework yang digunakan untuk *crawl* sebuah web dan mengekstrak data dari halaman web tersebut.\n",
    "\n",
    "```{tip}\n",
    "Perbedaan *framework* dan *library* terletak pada kontrol penggunaannya dalam sebuah program {cite}`framework-library-diff`.\n",
    "* **Framework** meminta kita untuk menyediakan apa saja yang diperlukan untuk menggunakannya.\n",
    "* **Library** mengizinkan kita untuk menggunakannya di manapun dan kapanpun.\n",
    "```\n",
    "\n",
    "## Creating A Spider\n",
    "\n",
    "Scrapy menggunakan istilah \"*spider*\" yang merupakan *crawler* utama untuk \"merayapi\" halaman sebuah web. Untuk itu, kita perlu membuat *spider* yang didefinisikan dalam sebuah *class*. Secara umum, struktur kode yang akan kita buat adalah seperti berikut.\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class DSJobCrawler(scrapy.Spider):\n",
    "    name = \"ds_job_crawler\"\n",
    "    # instructions for spiders to follow\n",
    "    ...\n",
    "\n",
    "\n",
    "# initiate CrawlerProcess\n",
    "crawler = CrawlerProcess()\n",
    "\n",
    "# assign which spider to use\n",
    "crawler.crawl(DSJobCrawler)\n",
    "\n",
    "# start crawling\n",
    "crawler.start()\n",
    "```\n",
    "\n",
    "### Imports\n",
    "\n",
    "Pertama, kita lakukan impor framework `scrapy` dan class `CrawlerProcess` yang akan kita gunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23519b6-4ce5-4316-9125-1fdd1d25f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c777bf-6d18-486a-9697-a3d0d327c44e",
   "metadata": {},
   "source": [
    "Kita hanya memerlukan 2 *library* saja, yaitu *scrapy* dan *csv*. Sebelum kita impor, kita harus pastikan bahwa `scrapy` sudah terpasang atau belum. Jika belum, kita bisa *install* terlebih dahulu.\n",
    "\n",
    "```bash\n",
    "pip install Scrapy\n",
    "```\n",
    "\n",
    "```{tip}\n",
    "Untuk kemudahan, silakan akses notebook ini menggunakan Deepnote melalui link berikut: [Web Scraping with Python](https://deepnote.com/project/Bitlabs-Webinar-Participants-dLC-FtPnTVCYE2M7i68cCw/%2Fscraping.ipynb)\n",
    "```\n",
    "\n",
    "Supaya lebih sederhana, kita hanya akan mengumpulkan data lowongan pekerjaan *data scientist* dari [Indeed](https://id.indeed.com/). Data lowongan itu akan kita simpan dalam sebuah file berformat CSV, `data_scientist_job.csv`. Kita akan coba mengekstrak beberapa informasi berikut:\n",
    "* `job_title` → Judul pekerjaan\n",
    "* `job_link` → Tautan lowongan pekerjaan di Indeed\n",
    "* `company` → Nama perusahaan\n",
    "* `company_rating` → Penilaian perusahaan berdasarkan pengguna Indeed\n",
    "* `company_reviews` → Jumlah ulasan perusahaan oleh pengguna Indeed\n",
    "* `apply_link` → Tautan untuk melamar pekerjaan\n",
    "\n",
    "Oleh karena itu, terlebih dahulu kita buat file tersebut, `data_roles_job.csv`, yang hanya berisi informasi-informasi di atas menggunakan kode di bawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386be581-aaa4-405c-b60b-917465bd05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_storage_file = \"data_roles_job.csv\"\n",
    "with open(job_storage_file, \"w\") as out_file:\n",
    "    writer = csv.DictWriter(\n",
    "        out_file,\n",
    "        fieldnames=[\n",
    "            \"job_title\", \"job_link\", \"company\", \"company_rating\", \"company_reviews\",\n",
    "            \"job_type\", \"job_location\", \"salary\", \"job_desc\", \"apply_link\"\n",
    "        ]\n",
    "    )\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc062b-663f-4f1c-ba32-bc76fc3ff15d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Spider Class*\n",
    "\n",
    "Selanjutnya, kita buat *class* `DSJobCrawler` yang akan mengekstrak informasi yang disebutkan sebelumnya. Dalam mendefinisikan *class* tersebut, kita akan bagi ke dalam beberapa komponen:\n",
    "1. Konfigurasi awal *spider*\n",
    "2. Instruksi *gateaway*\n",
    "3. Instruksi ekstraksi informasi\n",
    "\n",
    "\n",
    "#### 1. Konfigurasi Awal *Spider*\n",
    "\n",
    "Pertama, kita gunakan kode di bawah ini.\n",
    "\n",
    "```python\n",
    "class DSJobCrawler(scrapy.Spider):\n",
    "    name = \"ds_job_crawler\"\n",
    "    start_urls = [\n",
    "        \"https://id.indeed.com/lowongan-kerja-data-scientist-di-Indonesia\",\n",
    "        \"https://id.indeed.com/jobs?q=Data+Science&l=Indonesia\"\n",
    "    ]\n",
    "    custom_settings = {\"DOWNLOAD_DELAY\": .25}\n",
    "```\n",
    "\n",
    "```{figure} ../assets/images/scrape-init.png\n",
    ":name: scrape-init\n",
    "Pendefinisian *crawler*\n",
    "```\n",
    "\n",
    "* `class DSJobCrawler(scrapy.Spider)` → *class* yang digunakan kita namai dengan `DSJobCrawler` yang mewarisi *class* `scrapy.Spider`. Pewarisan (*inheritance*) ini wajib hukumnya agar *scrapy* bisa berjalan.\n",
    "\n",
    "    ```{note}\n",
    "    Penjelasan lebih lanjut tentang *inheritance* bisa dieksplor di [artikel berikut](https://realpython.com/inheritance-composition-python/https://realpython.com/inheritance-composition-python/).\n",
    "    ```\n",
    "\n",
    "* `name` → nama *spider*\n",
    "* `start_urls` → URL yang akan kita ekstrak informasinyaURL yang akan kita ekstrak informasinya\n",
    "* `custom_settings` → konfigurasi pada *spider* yang nilainya kita tentukan sendirikonfigurasi pada *spider* yang nilainya kita tentukan sendiri\n",
    "\n",
    "\n",
    "#### 2. Instruksi *Gateaway*\n",
    "\n",
    "Selanjutnya, kita akan mendefinisikan metode `parse` pada *class* `DSJobCrawler` yang pada kasus ini berfungsi sebagai sebuah *gateaway*. Maksud dari *gateaway* di sini adalah `parse` akan berfungsi sebagai gerbang masuk utama yang membantu mengarahkan tautan halaman yang akan diproses. Ini biasanya digunakan ketika kita tertarik untuk mengekstrak informasi dari **beberapa halaman**.\n",
    "\n",
    "Sebagai contoh, jika kita lihat contoh tampilan halaman pada Indeed berikut, setiap halaman mempunyai daftar lowongan pekerjaan. Kita tertarik untuk mengekstrak informasi dari setiap lowongan yang ada di halaman 1, 2, dan seterusnya.\n",
    "\n",
    "```{figure} ../assets/images/indeed-example.png\n",
    ":name: indeed-example\n",
    "Contoh tampilan laman Indeed\n",
    "```\n",
    "\n",
    "Kita akan menggunakan potongan kode berikut.\n",
    "\n",
    "```python\n",
    "    ...\n",
    "    def parse(self, response):\n",
    "        current_page = response.css(\"ul.pagination-list\").xpath(\n",
    "            \".//*[contains(@aria-current, 'true')]\"\n",
    "        ).attrib.get(\"aria-label\")\n",
    "        self.logger.debug(\"current page: %s\", current_page)\n",
    "        \n",
    "        try:\n",
    "            next_page = response.css(\"ul.pagination-list\").xpath(\n",
    "                \".//*[contains(@aria-label, '{}')]\".format(int(current_page) + 1)\n",
    "            ).attrib[\"href\"]\n",
    "        except:\n",
    "            self.logger.info(\"Couldn't find next page. Done extracting\")\n",
    "        else:\n",
    "            if current_page:\n",
    "                current_page += 1\n",
    "                yield response.follow(next_page, callback=self.parse, meta={\"dont_redirect\": True})\n",
    "\n",
    "        for job_link in response.css(\"a.tapItem::attr(href)\").getall():\n",
    "            yield response.follow(job_link, callback=self.parse_detail)\n",
    "    ...\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "`...` adalah kode sebelum dan sesudah definisi metode tersebut.\n",
    "```\n",
    "\n",
    "```{figure} ../assets/images/scrape-parse.png\n",
    ":name: scrape-parse\n",
    "Metode `parse` menerapkan fungsi rekursif untuk memroses tiap halaman dan mengarahkan ke metode `parse_detail` untuk memroses detil informasi lowongan\n",
    "```\n",
    "\n",
    "\n",
    "#### 3. Instruksi Ekstraksi Informasi\n",
    "\n",
    "Jika kita perhatikan pada metode `parse` di atas, ada bagian perulangan `for job_link in response...` yang menggunakan `response.follow` untuk meneruskan **setiap tautan detail lowongan** ke fungsi *callback* `parse_detail`. Metode inilah yang akan digunakan untuk mengekstrak semua informasi yang ada pada halaman detail lowongan pekerjaan.\n",
    "\n",
    "Perlu diperhatikan juga bahwa setiap detail informasi pada lowongan pekerjaan pasti berbeda satu dengan yang lainnya, baik secara format penulisan dan kelengkapan informasi. Oleh karena itu, sangat wajar ketika informasi yang kita ekstrak tidak sempurna.\n",
    "\n",
    "```{figure} ../assets/images/job-ex.png\n",
    ":name: job-example\n",
    "(kiri) lowongan pekerjaan 1. (kanan) lowongan pekerjaan 2.\n",
    "```\n",
    "\n",
    "Untuk itu, kita gunakan kode di bawah ini.\n",
    "\n",
    "```python\n",
    "    ...\n",
    "    def parse_detail(self, response):\n",
    "        company_info = response.xpath(\"//div[contains(@class, 'InlineCompanyRating')]\")\n",
    "        list_job_desc = [\n",
    "            text.strip() for text in\n",
    "            response.xpath(\"//div[contains(@class, 'jobDescriptionText')]\").css(\"::text\").getall()\n",
    "        ]\n",
    "        job_subtitle = [subtitle.get() for subtitle in response.xpath(\"//div[contains(@class, 'JobInfoHeader-subtitle')]/*/text()\")]\n",
    "        job_detail = {\n",
    "            \"job_title\": response.css(\"h1::text\").get(),\n",
    "            \"job_link\": response.url,\n",
    "            \"company\": company_info.xpath(\".//a/text()\").get() or company_info.xpath(\".//div/text()\").get(),\n",
    "            \"company_rating\": company_info.xpath(\".//meta[contains(@itemprop, 'ratingValue')]\").attrib.get(\"content\"),\n",
    "            \"company_reviews\": company_info.xpath(\".//meta[contains(@itemprop, 'ratingCount')]\").attrib.get(\"content\"),\n",
    "            \"job_location\": job_subtitle[0],\n",
    "            \"job_type\": job_subtitle[1] if len(job_subtitle) > 1 else \"\",\n",
    "            \"salary\": response.xpath(\"//div[contains(@class, 'JobMetadataHeader')]/span/text()\").get(),\n",
    "            \"job_desc\": \" \".join(list_job_desc),\n",
    "            \"apply_link\": response.xpath(\"//div[contains(@id, 'applyButtonLinkContainer')]\").css(\"a::attr(href)\").get()\n",
    "        }\n",
    "        if not job_detail.get(\"company\"):\n",
    "            self.logger.debug(\"Got no company info: %s\", response.url)\n",
    "\n",
    "        with open(job_storage_file, \"a\") as out_file:\n",
    "            writer = csv.DictWriter(out_file, fieldnames=job_detail.keys())\n",
    "            writer.writerow(job_detail)\n",
    "```\n",
    "\n",
    "```{figure} ../assets/images/scrape-detail.png\n",
    ":name: scrape-detail\n",
    "Metode `scrape_detail` melakukan pra-pemrosesan tag HTML, menyimpan dalam sebuah `dictionary`, yang kemudian disimpan dalam file CSV\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad889bf-8ab5-499e-bb5c-53129fe1061e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run The Crawler\n",
    "\n",
    "Setelah semua komponen sudah siap dan dijadikan dalam satu *class*. Kita bisa langsung mengekstrak semua lowongan pekerjaan di Indeed menggunakan kode berikut ini.\n",
    "\n",
    "```python\n",
    "crawler = CrawlerProcess()\n",
    "crawler.crawl(DSJobCrawler)\n",
    "crawler.start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5cd940-86ad-413a-a329-bd7d1812d1f7",
   "metadata": {},
   "source": [
    "## Contoh Hasil\n",
    "\n",
    "Jika proses ekstraksi kita berhasil, kita akan mendapatkan data lowongan pekerjaan beserta informasi yang kita ingingkan seperti ilustrasi di bawah ini.\n",
    "\n",
    "```{figure} ../assets/images/result-ex.png\n",
    ":name: result-example\n",
    "Contoh hasil ekstraksi Scrapy\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
